{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "\n",
    "# Graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load images\n",
    "from IPython.display import Image\n",
    "\n",
    "# Warning\n",
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "\n",
    "# Feature selection\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "# Save files\n",
    "import pickle\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning models\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "# Model's cross-validation\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# Model's metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's performance function\n",
    "def error(model, y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    root_mse = np.sqrt(mean_absolute_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rs = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return pd.DataFrame( {\n",
    "        'Model' : model,\n",
    "        'MAE' : mae,\n",
    "        'R2' : rs,\n",
    "        'MSE' : mae,\n",
    "        'RMSE' : root_mse\n",
    "           \n",
    "    }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers function\n",
    "def drop_outliers(var: str, dataset: pd.DataFrame):\n",
    "\n",
    "    # find Q1, Q3 e IQR\n",
    "    Q1 = np.quantile(dataset[var], .25)\n",
    "    Q3 = np.quantile(dataset[var], .75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # calculates the outliers boundaries through statistical relationship\n",
    "    low = Q1 - 1.5 * IQR\n",
    "    high = Q3 + 1.5 * IQR\n",
    "\n",
    "    data_results = dataset.loc[(dataset[var] > low) & (dataset[var] < high)]\n",
    "    return data_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting Relashionship\n",
    "def relashionship_h(dataset: pd.DataFrame, var1: str, var2: str):\n",
    "    # Selecting columns to groupby\n",
    "    h = dataset.groupby(var2)[var1].sum().reset_index()\n",
    "    h_mean = dataset.groupby(var1)[var2].mean().reset_index()\n",
    "\n",
    "    # Plotting\n",
    "    f, ax = plt.subplots(3, 1,figsize=(16, 6))\n",
    "    sns.scatterplot(data=h, y=var1, x=var2, ax=ax[0], color='g', alpha=0.08)\n",
    "    ax[0].set_title(f'Sum of {var1} x {var2}')\n",
    "    sns.regplot(data=h_mean, y=var1, x=var2, ax=ax[1])\n",
    "    ax[1].set_title(f'Mean of {var1} x {var2}')\n",
    "    plt.subplot(3, 1, 3)\n",
    "    sns.heatmap(data=h.corr(method='pearson'), annot=True)\n",
    "    plt.subplots_adjust(hspace=0.8)\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Function\n",
    "\n",
    "def cross_validation(model_name, model, x, y):\n",
    "\n",
    "    # Error lists to concatenate the values\n",
    "    mse_list = cross_val_score(model, x, y, scoring='neg_mean_absolute_error', cv=5)\n",
    "    rmse_list = cross_val_score(model, x, y, scoring='neg_mean_squared_error', cv=5)\n",
    "    mae_list = cross_val_score(model, x, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "    r2_list = cross_val_score(model, x, y, scoring='r2', cv=5)\n",
    "\n",
    "    return pd.DataFrame( {\n",
    "        'Model Name' : model_name,\n",
    "        'MAE' : np.round(np.mean(-mae_list), 4).astype(str) + ' +/- ' + np.round(np.std(-mae_list), 4).astype(str),\n",
    "        'R2' : np.mean(r2_list),\n",
    "        'MSE' : np.round(np.mean(-mse_list), 4).astype(str) + ' +/- ' + np.round(np.std(-mse_list), 4).astype(str),\n",
    "        'RSME' : np.round(np.mean(-rmse_list), 4).astype(str) + ' +/- ' + np.round(np.std(-rmse_list), 4).astype(str)\n",
    "    }, index=[0])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset using pandas\n",
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Columns Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features:**\n",
    "\n",
    "  *Numerical:*\n",
    "\n",
    "  - **Acousticness** (Ranges from 0 to 1): The relative metric of the track being acoustic. 1.0 represents high confidence the track is acoustic\n",
    "  - **Danceability** (Ranges from 0 to 1): The relative measurement of the track being danceable. Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable\n",
    "  - **Energy** (Ranges from 0 to 1): The energy of the track. Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy\n",
    "  - **duration_ms** (Integer typically ranging from 200k to 300k): The length of the track in milliseconds (ms)\n",
    "  - **instrumentalness** (Ranges from 0 to 1): The relative ratio of the track being instrumental. Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0\n",
    "  - **valence** (Ranges from 0 to 1): A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry)\n",
    "  - **popularity** (Ranges from 0 to 100)\n",
    "  - **tempo** (Float typically ranging from 50 to 150): The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration\n",
    "  - **liveness** (Ranges from 0 to 1): Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live\n",
    "  - **loudness** (Float typically ranging from -60 to 0): The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db\n",
    "  - **speechiness** (Ranges from 0 to 1): Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks\n",
    "  - year (Ranges from 1921 to 2020)\n",
    "\n",
    "*Dummy:*\n",
    "\n",
    "  - **mode** (0 = Minor, 1 = Major): Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0\n",
    "  - **explicit** (0 = No explicit content, 1 = Explicit content): Whether or not the track has explicit lyrics ( true = yes it does; false = no it does not OR unknown)\n",
    "\n",
    "*Categorical:*\n",
    "\n",
    "  - **key** (All keys on octave encoded as values ranging from 0 to 11, starting on C as 0, C# as 1 and so on…)\n",
    "  - **artists** (List of artists mentioned)\n",
    "  - **release_date** (Date of release mostly in yyyy-mm-dd format, however precision of date may vary)\n",
    "  - **name** (Name of the song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Rename Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not necessary to change columns name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Data Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The dimension of data is: {df.shape}.')\n",
    "print(f'Number of rows: 170653.')\n",
    "print(f'Number of columns: 19.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Data Types and Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No Null Values\n",
    "* The dataset has 3 types: float64(9), int64(6) and object(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Change Data Types\n",
    "It is not necessary to change data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6.1. Numerical Atrributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical attributes\n",
    "num_attr = df.select_dtypes(include=['int64', 'float64'])\n",
    "num_attr.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6.2. Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attr = df.select_dtypes(exclude=['float64', 'int64'])\n",
    "cat_attr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These columns will not be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration in minutes\n",
    "df['duration_min'] = df.duration_ms / (60*1000)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Mind Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('img/mindset.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Hypothesis Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Audio Feature Object\n",
    "1. Popularity occur with high `acousticness`.\n",
    "2. Popularity occur with high `danceability`.\n",
    "3. Popularity occur with 80% of `liveness`.\n",
    "4. Popularity occur with `loudness` above -10.\n",
    "5. Popularity occur with low `energy`.\n",
    "6. Popularity occur with low `speechiness`.\n",
    "7. Popularity occur with high `valence`.\n",
    "8. Popularity occur with `key` equal 2.\n",
    "9. Popularity occur with `mode` equal 1.\n",
    "10. Popularity occur with high `tempo`.\n",
    "11. Popularity occur with low `instrumentalness`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Track\n",
    "1. Popularity occur with `explicit` equal 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Time\n",
    "1. Popularity occur with high `duration_min`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0. Variables Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_outline = 'duration_ms'\n",
    "df3 = df2[df2.duration_ms < 2e6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 1 \n",
    "# df3.to_csv('dataset/df3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Univariate Analysis\n",
    "The univariate analysis explores the variable itself, so that can be checked the variable frequency, distribution, range. Etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Target Variable\n",
    "Target Variable Popularity: It is calculated by an algorithm and based on how many times a track has been played and how recent those plays are.\n",
    "\n",
    "The popularity of a track is a value between 0 and 100, with 100 being the most popular. The popularity is calculated by algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are.\n",
    "Generally speaking, songs that are being played a lot now will have a higher popularity than songs that were played a lot in the past. Duplicate tracks (e.g. the same track from a single and an album) are rated independently. Artist and album popularity is derived mathematically from track popularity. Note that the popularity value may lag actual popularity by a few days: the value is not updated in real time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Checkpoint 1\n",
    "df3 = pd.read_csv('dataset/df3.csv').drop(['Unnamed: 0', 'duration_ms'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_numerical = df3.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Median and Mean\n",
    "pop_mean = df3_numerical.popularity.mean()\n",
    "pop_median = df3_numerical.popularity.median()\n",
    "\n",
    "# Plot target variable\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.histplot(df3_numerical.popularity, color='gray')\n",
    "plt.axvline(pop_median, color = 'b', linewidth = 1, label = 'median')\n",
    "plt.axvline(pop_mean, color='g', linewidth = 1, label = 'mean')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most of the songs do not have good popularity score.\n",
    "* Popularity has a multimodal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot target variable by year\n",
    "plt.figure(figsize=(16, 5))\n",
    "sns.lineplot(data=df3_numerical, x='year', y='popularity', ci=None, color='gray')\n",
    "plt.xticks(np.arange(1921, 2022, 10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* About 0 popularity: This means all songs related to an artist are 0-popular. \n",
    "* These songs are songs from 1920s or maybe older. \n",
    "* It has anything to do with the popularity measurement system, not the dataset itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Numerical Variables Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting numerical \n",
    "plt.figure(figsize=(16,8))\n",
    "df3_numerical.hist(bins=25, figsize=(20,15), color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**\n",
    "* `loudness` has negative values and left skew\n",
    "* `liveness`, `speechiness` and `duration_min` is right skew\n",
    "* `loudness` has negative skew\n",
    "* `tempo` has a unimodal distribution\n",
    "* `acousticness` is a bimodal dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outliers\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "for i in range(len(df3_numerical.columns)):\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    sns.boxplot(df3_numerical[df3_numerical.columns[i]], color='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Categorical Variables Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. Artists of the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with actual top artists\n",
    "top_hit_artists = df3.groupby('artists')[['popularity']].mean().reset_index()\n",
    "top_hit_artists = top_hit_artists.sort_values(by='popularity', ascending=False).head(30)\n",
    "\n",
    "# Ploting\n",
    "plt.figure(figsize=(16,5))\n",
    "sns.barplot(data=top_hit_artists, x='artists', y='popularity')\n",
    "plt.title('Top Artists of the Moment')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. Songs of the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with top hit musics\n",
    "top_hit_music = df3.groupby('name')[['popularity']].mean().reset_index()\n",
    "top_hit_music = top_hit_music.sort_values(by='popularity', ascending=False).head(30)\n",
    "\n",
    "# Ploting\n",
    "plt.figure(figsize=(16,5))\n",
    "sns.barplot(data=top_hit_music, x='name', y='popularity')\n",
    "plt.title('Top Songs of the Moment')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3. Top famous artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with actual top artists\n",
    "top_hit_artists = df3.groupby('artists')[['popularity']].sum().reset_index()\n",
    "top_hit_artists = top_hit_artists.sort_values(by='popularity', ascending=False).head(30)\n",
    "\n",
    "# Ploting\n",
    "plt.figure(figsize=(16,5))\n",
    "sns.barplot(data=top_hit_artists, x='artists', y='popularity')\n",
    "plt.title('Top Famous Artists')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4. Top famous song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with top hit musics\n",
    "top_hit_music = df3.groupby('name')[['popularity']].sum().reset_index()\n",
    "top_hit_music = top_hit_music.sort_values(by='popularity', ascending=False).head(30)\n",
    "\n",
    "# Ploting\n",
    "plt.figure(figsize=(16,5))\n",
    "sns.barplot(data=top_hit_music, x='name', y='popularity')\n",
    "plt.title('Top Famous Music')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Bivariate Analysis\n",
    "The bivariate analysis consists of the independent variable analysis with respect to the dependent variable (target). It can be divided into two perspectives:\n",
    "\n",
    "1. Hypothesis validation or rejection - is it possible to generate an insight?\n",
    "2. Is the independent variable relevant for the model?\n",
    "\n",
    "The following analysis and graphs were made based on the hypothesis list previously issued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H1. Popularity occur with high `acousticness`.\n",
    "* FALSE\n",
    "*  HIGH RELEVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Help Function session\n",
    "relashionship_h(df3, 'popularity', 'acousticness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2. Popularity occur with high `danceability`.\n",
    "* TRUE\n",
    "* HIGH RELEVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relashionship_h(df3, 'popularity', 'danceability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H3. Popularity occur with 80% of `liveness`.\n",
    "* FALSE\n",
    "* LOW RELEVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relashionship_h(df3, 'popularity', 'liveness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H4. Popularity occur with `loudness` above -10.\n",
    "* TRUE\n",
    "* HIGH RELEVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relashionship_h(df3, 'popularity', 'loudness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H5. Popularity occur with low `energy`.\n",
    "* FALSE\n",
    "* HIGH RELEVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relashionship_h(df3, 'popularity', 'energy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H6. Popularity occur with low `speechiness`.\n",
    "* TRUE\n",
    "* LOW RELEVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relashionship_h(df3, 'popularity', 'speechiness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H7. Popularity occur with high `valence`.\n",
    "* FALSE\n",
    "* HIGH RELEVANCE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relashionship_h(df3, 'popularity', 'valence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H8. Popularity occur with `key` equal 2.\n",
    "* DEPEND\n",
    "* LOW RELEVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relashionship_h(df3, 'popularity', 'key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H9. Popularity occur with `mode` equal 1.\n",
    "* FALSE\n",
    "* HIGH RELEVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relashionship_h(df3, 'popularity', 'mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H10. Popularity occur with high `tempo`.\n",
    "* TRUE\n",
    "* LOW RELEVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relashionship_h(df3, 'popularity', 'tempo' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H11. Popularity occur with low `instrumentalness`.\n",
    "* TRUE\n",
    "* LOW RELEVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relashionship_h(df3, 'popularity', 'instrumentalness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H12. Popularity occur with `explicit` equal 1.\n",
    "* TRUE\n",
    "* LOW RELEVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relashionship_h(df3, 'popularity', 'explicit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H13. Popularity occour with high `duration_min`.\n",
    "* FALSE\n",
    "* LOW RELEVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relashionship_h(df3, 'popularity','duration_min' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Multivariate Analysis\n",
    "The main goal of the multivariate analysis is to check how variables are related. This is important because it can show the variables with strong or weak relation. The weak ones can later be removed in order to reduce the dataset dimensionality, hence reduce model’s complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "sns.heatmap(df3_numerical.corr(), annot=True, cmap='YlGnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0. Data Preparation\n",
    "Most of the Data Science problems, and this one is also included, have many different sorts of values in the dataset, which represents different range of values. For example, the variable month have a range from 1 to 12, while the competition distance variable has values up to 200000. That can difficult the machine learning training. Furthermore, the categorical variables are in most of the cases with text information, which the machine learning algorithm cannot interpret. To solve this is issue, the data must be prepared (a.k.a. preprocessed) so that the machine learning model can properly train and deliver high performance results.\n",
    "\n",
    "There are mainly three types of data preparation:\n",
    "\n",
    "- **Normalization:** Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1. It is also known as Min-Max scaling. Is good to use when you know that the distribution of your data does not follow a Gaussian distribution. This can be useful in algorithms that do not assume any distribution of the data.\n",
    "- **Standardization:** Standardization is another scaling technique where the values are centered around the mean with a unit standard deviation. This means that the mean of the attribute becomes zero and the resultant distribution has a unit standard deviation. Can be helpful in cases where the data follows a Gaussian distribution. However, this does not have to be necessarily true. Also, unlike normalization, standardization does not have a bounding range. So, even if you have outliers in your data, they will not be affected by standardization.\n",
    "- Transformation:\n",
    "  - Conversion of categorical variables to numerical (Encoding);\n",
    "  - Nature transformation for variables with cyclic nature (for example months of the year);\n",
    "  - Logarithm transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3_numerical.copy()\n",
    "df4.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outliers\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "for i in range(len(df3_numerical.columns)):\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    sns.boxplot(df3_numerical[df3_numerical.columns[i]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the numerical variables have a normal distribution (see subsection 4.2), therefore the Standardization will not be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust Scaler for variables with high outlier influence\n",
    "cols_rs = ['instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'duration_min']\n",
    "rs = RobustScaler()\n",
    "df4[cols_rs] = rs.fit_transform(df4[cols_rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler for variables with low outliers influence\n",
    "cols_mms = ['valence', 'year', 'acousticness', 'danceability', 'energy', 'explicit', 'key', 'mode', 'popularity']\n",
    "mms = MinMaxScaler()\n",
    "df4[cols_mms] = mms.fit_transform(df4[cols_mms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the categorical variables were used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove target variable\n",
    "X_train = df4.drop('popularity', axis=1)\n",
    "\n",
    "# Target variable\n",
    "y_train = df4['popularity'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Boruta as Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabled in order to not run again, since it takes a considerable time\n",
    "\n",
    "# Train random forest classifier\n",
    "\n",
    "# x_train\n",
    "#x_train_n = X_train.values\n",
    "\n",
    "#y_train_n = y_train.values\n",
    "#y_train_n = y_train.values.ravel()\n",
    "\n",
    "# Define random forest regression\n",
    "#rf = RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "# Define Boruta feature selection method\n",
    "#feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)\n",
    "\n",
    "# Find all relevant features\n",
    "#feat_selector.fit(x_train_n, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check selected features\n",
    "#cols_selected = feat_selector.support_.tolist()\n",
    "#cols_selected_boruta = df4.drop('popularity', axis=1).iloc[:, cols_selected].columns.to_list()\n",
    "#cols_selected_boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 2 \n",
    "# df4.to_csv('dataset/df4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0. Machine Learning Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "df5 = pd.read_csv('dataset/df4.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with Boruta selection\n",
    "df_boruta = df5[['year',\n",
    " 'acousticness',\n",
    " 'danceability',\n",
    " 'energy',\n",
    " 'instrumentalness',\n",
    " 'liveness',\n",
    " 'loudness',\n",
    " 'speechiness',\n",
    " 'tempo',\n",
    " 'duration_min']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish model features and split data between training and test set\n",
    "\n",
    "x = df_boruta.values\n",
    "y = y_train.values\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit model\n",
    "linear_r = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "lr_pred = linear_r.predict(x_test)\n",
    "\n",
    "# Evaluate\n",
    "lr_error = error('Linear Regression', y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1. Linear Regression Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_r_cv = cross_validation('Linear Regression CV', linear_r, x, y)\n",
    "linear_r_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabled in order to not run again, since it takes a considerable time\n",
    "\n",
    "# Define and fit model\n",
    "# rfr = RandomForestRegressor().fit(x_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "# rfr_pred = rfr.predict(x_test)\n",
    "\n",
    "# Evaluate\n",
    "# rfr_error = error('Random Forest Regression', y_test, rfr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfr_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1. Random Forest Regression Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfr_cv = cross_validation('Random Forest CV', rfr, x, y)\n",
    "# rfr_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fit model\n",
    "xgb = XGBRegressor(objective='reg:squarederror').fit(x_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "xgb_pred = xgb.predict(x_test)\n",
    "\n",
    "# Evaluate\n",
    "xgbr_error = error('XGBooster Regression', y_test, xgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.1. XGBoost Regressor Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv = cross_validation('XGBoost CV', xgb, x, y)\n",
    "xgb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6. Compare Model's Performance  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.1. Single Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sp = pd.concat([lr_error, rfr_error, xgbr_error])\n",
    "model_sp.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.2. Real Performance - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rp = pd.concat([linear_r_cv, rfr_cv, xgb_cv])\n",
    "model_rp.sort_values('RSME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained data\n",
    "# pickle.dump(xgb, open('model/xgb_cv.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0. Fine Tuning \n",
    "The hyperparameter fine-tuning is performed in order to improve the model performance in comparison to the model with default hyperparameters.\n",
    "\n",
    "There are two ways to perform hyperparameter fine-tuning: through grid search or through random search. In grid search all predefined hyperparameters are combined and evaluated through cross-validation. It is the best way to find the best hyperparameters combinations, however it takes a long time to be completed. In random search, the predefined hyperparameters are randomly combined and then evaluated through cross-validation. It may not find the best optimal combination, however it is much faster than the grid search and it is largely applied.\n",
    "\n",
    "In this project, the sklearn's RandomizedSearchCV was initially applied, however it did not work as expected and therefore was not able to complete the task. Hence, the code lines were removed in order to keep the functional script in the notebook. This problem is probably due to: 1. the size of the dataset and 2. The computer memory.\n",
    "\n",
    "As the random search executes a cross-validation for each iterations (i.e., for each random hyperparameter combination), the execution and values are stored in the RAM memory, which due to the size of the dataset cannot afford all these steps. Hence, in order to experiment other hyperparameter combinations rather than the default one, three combinations were randomly set and evaluated on the test set, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "# xgboost_regression_cv = pickle.load(open('model/xgb_cv.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabled in order to not run again, since it takes 591.9 minutes\n",
    "# Params\n",
    "#parameters = {\n",
    "#              'objective': ['reg:squarederror'],\n",
    "#              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "#              'max_depth': [3, 5, 9],\n",
    "#              'min_child_weight': [4],\n",
    "#              'silent': [1],\n",
    "#              'subsample': [0.1, 0.5, 0.7],\n",
    "#              'colsample_bytree': [0.3, 0.7, 0.9],\n",
    "#              'n_estimators': [1500, 1700, 2500, 3000, 3500]}\n",
    "\n",
    "#xgb_grid = GridSearchCV(xgboost_regression_cv,\n",
    "#                        parameters,\n",
    "#                        cv = 2,\n",
    "#                        n_jobs = 5,\n",
    "#                        verbose=True).fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving GridSearchCV\n",
    "# pickle.dump(xgb_grid, open('model/xgb_grid.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "xgboost_Best_params = pickle.load( open('model/xgb_grid.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_Best_params.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict with values from the GridSearchCV\n",
    "param_tuned = {'colsample_bytree': 0.9,\n",
    " 'learning_rate': 0.03,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 4,\n",
    " 'n_estimators': 1500,\n",
    " 'objective': 'reg:squarederror',\n",
    " 'silent': 1,\n",
    " 'subsample': 0.7\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabled in order to not run again, since it takes a considerable time\n",
    "\n",
    "# Tuned Model\n",
    "#xgb_tuned = XGBRegressor(\n",
    "#    objective = 'reg:squarederror',\n",
    "#    colsample_bytree= 0.9,\n",
    "#    learning_rate= 0.03,\n",
    "#    max_depth= 5,\n",
    "#    min_child_weight= 4,\n",
    "#    n_estimators= 1500,\n",
    "#    silent= 1,\n",
    "#    subsample= 0.7\n",
    "#    ).fit(x_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "#xgb_tuned_pred = xgb_tuned.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabled in order to not run again, since it takes a considerable time\n",
    "\n",
    "# Evaluate\n",
    "# xgbr_tuned_error = error('XGBooster Regression+', y_test, xgb_tuned_pred)\n",
    "# xgbr_tuned_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving GridSearchCV\n",
    "# pickle.dump(xgb_tuned, open('model/xgb_tuned.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2. Cross Validation Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabled in order to not run again, since it takes a considerable time\n",
    "\n",
    "# XGBoost tuned cross-validation\n",
    "# xgb_cv_t = cross_validation('XGBoost CV +', xgb_t, x, y)\n",
    "# xgb_cv_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.0. Businesse Performance and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Single Performance Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all models\n",
    "model_rpf = pd.concat([linear_r_cv, rfr_cv, xgb_cv, xgb_cv_t])\n",
    "model_rpf.sort_values('RSME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Real Performance Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concoat all validation\n",
    "ml_rpf = pd.concat([model_rp, xgb_cv_t])\n",
    "ml_rpf.sort_values('RSME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3. Saving and Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Dataset for predictions\n",
    "# pd.DataFrame(x_test).to_csv('dataset/df6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Dataset for predictions\n",
    "df6 = pd.read_csv('dataset/df6.csv').drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "# Loading model\n",
    "xgb_t = pickle.load( open('model/xgb_tuned.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4. Machine Learning Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting columns\n",
    "columns_name = ['year', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'duration_min']\n",
    "columns_name2 = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# Zip columns\n",
    "d_columns = dict(zip(columns_name2, columns_name))\n",
    "\n",
    "# Changing columns names\n",
    "df7 = df6.rename(columns = d_columns)\n",
    "\n",
    "# Prediction column\n",
    "df7['prediction'] = np.expm1(xgb_t.predict(df7[df_boruta.columns]))\n",
    "\n",
    "# Target variable\n",
    "df7['popularity'] = np.expm1(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4.1. Error and Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets error\n",
    "df7['error'] = df7['popularity'] - df7['prediction']\n",
    "\n",
    "# Gets error rate\n",
    "df7['error_rate'] = df7['popularity'] / df7['prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.4.2. Ploting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Axis\n",
    "fig, ax = plt.subplots(figsize=(20,12))\n",
    "\n",
    "# Plot prediction x popularity\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.lineplot(data=df7, x= 'year', y='prediction', label='Prediction', color='r')\n",
    "sns.lineplot(data=df7, x='year', y='popularity', color='g', label='Popularity')\n",
    "plt.legend()\n",
    "\n",
    "# Plot error\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.lineplot(data=df7, x='year', y='error_rate', label='Error Rate')\n",
    "plt.axhline(1, linestyle='--')\n",
    "\n",
    "# Hist error\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(df7.error, color='gray')\n",
    "\n",
    "# Plot predictions x error\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(data=df7, x='prediction', y='error', color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "# Plot prediction x popularity\n",
    "sns.lineplot(data=df7, x='year', y='popularity', color='g', label='Popularity')\n",
    "sns.lineplot(data=df7, x= 'year', y='prediction', label='Prediction', color='r')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.lineplot(data=df7, x='year', y='error_rate', label='Error Rate')\n",
    "plt.axhline(1, linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.lineplot(data=df7, x='year', y='error_rate', label='Error Rate')\n",
    "plt.axhline(1, linestyle='--')\n",
    "plt.axis([0.3, 1, 0.8, 1.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.distplot(df7.error, color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.scatterplot(data=df7, x='prediction', y='error', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the results, we can see that:\n",
    "\n",
    "* By observing the first and second line plots, we can see that the predictions or our model is pretty close to the real value for sales. On the other hand, the error rate has some variance.\n",
    "\n",
    "* By observing the histogram, the error distribution almost follows a normal distribution.\n",
    "\n",
    "* By observing the scatterplot for the errors, the points seems well fit in a horizontal tube which means that there's a few variation in the error. If the points formed any other shape (e.g opening/closing cone or an arch), this would mean that the errors follows a trend and we would need to review our model."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
