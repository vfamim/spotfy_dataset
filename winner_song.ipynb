{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Introduction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# The Business Challenge"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Key points to understand a data science problem:**\n",
    "\n",
    "- What is the motivation? What is the context behind?\n",
    "- What is the root cause? Why does the business team need a forecast?\n",
    "- Who is the Stakeholder?\n",
    "- What is the expected solution format?\n",
    "\n",
    "In this case, the key point of the problem are:\n",
    "\n",
    "- **Request:** the CFO requested this solution to the business team in a management meeting;\n",
    "- **The root cause:** the CFO aims to reform the stores. However, it is extremely hard to determine the reform budget for each store;\n",
    "- **The Stakeholder:** The CFO is the Stakeholder;\n",
    "- Solution Format:\n",
    "  - **Granularity:** Daily sales forecast (in R$) per store for the next 6 weeks;\n",
    "  - **Problem Type:** Sales forecast;\n",
    "  - **Potential Methods:** Time Series, Regression, Neural Networks;\n",
    "  - **Output Shape:** Sales forecast displayed in a smartphone.\n",
    "\n",
    "The above-mentioned key points show that there is relevant content behind the 6 weeks sales forecast request: the final goal is to reform the stores. However, it is not possible to set a budget for that without knowing the revenue for the period: it is a risk, for example, if the reform budget exceeds the total amount of sales, that is, pratical there would not be enough money to finish the reform."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 0.0. Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 0.1. Helper Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1.0. Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.1. Load the Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.2. Columns Description"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.2.1. Rename Columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.3. Data Dimension"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.4. Data Types and Structure"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.5. Change Data Types\n",
    "It is not necessary to change data types."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.6. Descriptive Statistics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1.6.1. Numerical Atrributes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1.6.2. Categorical Attributes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 2.0. Feature Engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.1. Mind Map"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.2. Hypothesis Creation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 3.0. Variables Filtering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 4.0. Exploratory Data Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4.1. Univariate Analysis\n",
    "The univariate analysis explores the variable itself, so that can be checked the variable frequency, distribution, range. Etc.\n",
    "\n",
    "Below are the variables distribution graphics:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4.2. Numerical Variables Distribution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4.3. Categorical Variables Distribution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4.4. Bivariate Analysis\n",
    "The bivariate analysis consists of the independent variable analysis with respect to the dependent variable (target). It can be divided into two perspectives:\n",
    "\n",
    "1. Hypothesis validation or rejection - is it possible to generate an insight?\n",
    "2. Is the independent variable relevant for the model?\n",
    "\n",
    "The following analysis and graphs were made based on the hypothesis list previously issued."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4.5. Multivariate Analysis\n",
    "The main goal of the multivariate analysis is to check how variables are related. This is important because it can show the variables with strong or weak relation. The weak ones can later be removed in order to reduce the dataset dimensionality, hence reduce modelâ€™s complexity."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 4.5.1. Numerical Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 4.5.2. Categorical Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 5.0. Data Preparation\n",
    "Most of the Data Science problems, and this one is also included, have many different sorts of values in the dataset, which represents different range of values. For example, the variable month have a range from 1 to 12, while the competition distance variable has values up to 200000. That can difficult the machine learning training. Furthermore, the categorical variables are in most of the cases with text information, which the machine learning algorithm cannot interpret. To solve this is issue, the data must be prepared (a.k.a. preprocessed) so that the machine learning model can properly train and deliver high performance results.\n",
    "\n",
    "There are mainly three types of data preparation:\n",
    "\n",
    "- **Normalization:** Rescale the center (mean) to zero with standard deviation of 1, usually applied for variables with a normal, Gaussian distribution;\n",
    "- **Rescaling:** Rescale the numerical variable to a range between 0 and 1, normally applied for variables without a Gaussian distribution;\n",
    "- Transformation:\n",
    "  - Conversion of categorical variables to numerical (Encoding);\n",
    "  - Nature transformation for variables with cyclic nature (for example months of the year);\n",
    "  - Logarithm transformation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5.1. Rescaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5.2. Transformation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 6.0. Feature Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 7.0. Machine Learning Modelling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 8.0. Fine Tuning \n",
    "The hyperparameter fine-tuning is performed in order to improve the model performance in comparison to the model with default hyperparameters.\n",
    "\n",
    "There are two ways to perform hyperparameter fine-tuning: through grid search or through random search. In grid search all predefined hyperparameters are combined and evaluated through cross-validation. It is the best way to find the best hyperparameters combinations, however it takes a long time to be completed. In random search, the predefined hyperparameters are randomly combined and then evaluated through cross-validation. It may not find the best optimal combination, however it is much faster than the grid search and it is largely applied.\n",
    "\n",
    "In this project, the sklearn's RandomizedSearchCV was initially applied, however it did not work as expected and therefore was not able to complete the task. Hence, the code lines were removed in order to keep the functional script in the notebook. This problem is probably due to: 1. the size of the dataset and 2. The computer memory.\n",
    "\n",
    "As the random search executes a cross-validation for each iterations (i.e., for each random hyperparameter combination), the execution and values are stored in the RAM memory, which due to the size of the dataset cannot afford all these steps. Hence, in order to experiment other hyperparameter combinations rather than the default one, three combinations were randomly set and evaluated on the test set, as shown below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 10.0. Business Performance and Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}